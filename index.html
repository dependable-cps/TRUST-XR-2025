<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="Truest XR 2025" content="">
    <title>Truest XR 2025</title>
    <link rel="icon" href="images/favicon-32x32.png" type="image/png">
    <link href="./theme/css" rel="stylesheet">
    <link href="./theme/css(1)" rel="stylesheet">
    <link href="./theme/bootstrap.min.css" rel="stylesheet">
    <link href="./theme/bootstrap-theme.min.css" rel="stylesheet">
    <link href="./theme/icon.css" rel="stylesheet">
    <link href="./theme/ie10-viewport-bug-workaround.css" rel="stylesheet">
    <link href="./theme/style.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">


    <style>
        section {
            /* padding-top: 10px; */
            margin-top: -20px;
            scroll-margin-top: 80px;
            /* Prevents content overlap by navbar*/
        }
    </style>
</head>

<body>
    <nav class="navbar navbar-default navbar-fixed-top" style="font-size:18px; color: #333;">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar"
                    aria-expanded="false" aria-controls="navbar">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="#">
                    <img src="images/trustxr-logo.png" alt="TRUST-XR Logo"
                        style="height: 30px; margin-right: 10px; display: inline-block; vertical-align: middle;">
                    <span style="color: #222; font-size: 20px; vertical-align: middle;">Trust XR 2025</span>
                </a>


            </div>
            <div id="navbar" class="navbar-collapse collapse">
                <ul class="nav navbar-nav">
                    <li><a href="#workshop-description" style="color: #333;">About</a></li>
                    <!-- <li><a href="#target-researchers" style="color: #333;">Intended Participants</a></li> -->
                    <li><a href="#location" style="color: #333;">Logistics</a></li>
                    <li><a href="#keynote" style="color: #333;">Keynote</a></li>
                    <li><a href="#program" style="color: #333;">Program</a></li>
                    <li><a href="#organizers" style="color: #333;">Organizers</a></li>
                    <li><a href="#call-for-paper" style="color: #333;">Call for Paper</a></li>

                    <!-- <li><a href="#important-dates" style="color: #333;">Important Dates</a></li> -->
                    <!-- <li><a href="https://sensorssp.github.io/sensorssp23/" target="_blank">Past Workshop</a></li> -->
                </ul>
            </div>
        </div>
    </nav>
    <!-- <nav class="navbar navbar-default navbar-fixed-top">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="#">Trust XR 2025</a>
            </div>
            <div id="navbar" class="navbar-collapse collapse">
                <ul class="nav navbar-nav">
                    <li><a href="#workshop-description">Workshop Description</a></li>
                    <li><a href="#target-researchers">Intended Participants</a></li>
                    <li><a href="#call-for-paper">Call for Paper</a></li>
                    <li><a href="#organizers">Organizers</a></li>
                    <li><a href="#submission-guidelines">Submission Guidelines</a></li>
                    <li><a href="#important-dates">Important Dates</a></li>
              
                </ul>
            </div>
        </div>
    </nav> -->


    <div class="container theme-showcase" role="main">
        <section id="workshop-description" class="page-header">
            <!-- <div id="workshop-description" class="page-header"> -->
            <img src="images/trustXR.png" alt="TRUST-XR 2025 Banner"
                style="max-width:100%; margin-top:20px; border: 2px solid #ccc; border-radius: 10px;">
            <h2 style="margin-bottom: 20px; font-size: 28px; font-weight: 700; color: #333;">About the Workshop</h2>

            <!-- <div style="text-align: center; margin-bottom: 20px;">
                <img src="images/trustxr-logo.png" alt="TRUST-XR Logo" style="max-width: 300px;">
            </div> -->
            <font size="3">
                <p>
                    <span style="text-align: justify; display: block;">Extended Reality (XR) technologies increasingly
                        integrate into everyday life such as education,
                        healthcare, defense, workforce training, and entertainment,
                        the need for trustworthy, secure, and privacy-aware artificial intelligence (AI) becomes
                        critical.
                        XR systems capture
                        sensitive biometric and behavioral data,
                        use opaque AI models, and are vulnerable to adversarial manipulation.</span>
                </p>

                <p>
                    <span style="text-align: justify; display: block;"><strong>TRUST-XR 2025</strong> will explore
                        cross-disciplinary challenges in securing XR systems,
                        improving AI explainability, protecting immersive user data,
                        and developing fair and ethical XR interfaces powered by conventional and generative AI (e.g.,
                        large language models (LLMs)).
                        The workshop will foster discussion and innovation around privacy-preserving pipelines,
                        adversarial
                        resilience, and human-centered trust frameworks.</span>
                </p>

            </font>
            <!-- Trimmed text for brevity -->

            <!-- </div> -->
        </section>
        <section id="target-researchers" class="page-header">
            <div
                style="background-color: #f8f9fb; padding: 30px; border-radius: 12px; box-shadow: 0 3px 12px rgba(0,0,0,0.06);">
                <p style="font-size: 16px; color: #333;">Trust XR Workshop is for you, if you are:</p>
                <ul style="list-style: none; padding-left: 0;">
                    <span style="text-align: justify; display: block;">
                        <li style="margin-bottom: 15px;">
                            <i class="fa fa-user-circle" style="color: #0066cc; margin-right: 8px;"></i>
                            <strong>XR and Immersive Systems Researchers:</strong> Investigating the role of trust,
                            security, privacy, and ethics in extended reality environments using biometric and
                            multimodal
                            sensing data.
                        </li>
                        <li style="margin-bottom: 15px;">
                            <i class="fa fa-brain" style="color: #0066cc; margin-right: 8px;"></i>
                            <strong>AI and Machine Learning Experts:</strong> Developing explainable,
                            privacy-preserving,
                            and adversarially robust AI models for XR applications, including those powered by LLMs and
                            generative AI.
                        </li>
                        <li style="margin-bottom: 15px;">
                            <i class="fa fa-eye" style="color: #0066cc; margin-right: 8px;"></i>
                            <strong>Human-Computer Interaction (HCI) and Cognitive Security Scholars:</strong> Studying
                            user
                            trust, manipulation risks, and perception-aware attacks in AI-driven immersive experiences.
                        </li>
                        <li style="margin-bottom: 15px;">
                            <i class="fa fa-shield" style="color: #0066cc; margin-right: 8px;"></i>
                            <strong>Cybersecurity and Privacy Professionals:</strong> Focusing on real-time XR system
                            vulnerabilities, privacy leakage, multimodal sensor protection, and runtime-layer defense
                            strategies.
                        </li>
                        <li style="margin-bottom: 15px;">
                            <i class="fa fa-balance-scale" style="color: #0066cc; margin-right: 8px;"></i>
                            <strong>Ethics, Policy, and Responsible AI Advocates:</strong> Addressing fairness,
                            accountability, and regulatory compliance in intelligent XR systems, including responsible
                            deployment of black-box AI models.
                        </li>
                        <li style="margin-bottom: 15px;">
                            <i class="fa fa-cogs" style="color: #0066cc; margin-right: 8px;"></i>
                            <strong>Developers and System Architects:</strong> Building secure XR platforms and
                            pipelines
                            that balance immersive performance with safety, explainability, and user trust.
                        </li>
                    </span>
                </ul>
            </div>
            <div>

                <h3 style="font-size: 22px; margin-bottom: 10px;">Program Overview</h3>
                <p style="font-size: 16px; color: #333;">
                    TRUST-XR 2025 is a full-day hybrid workshop featuring expert talks, research presentations, and
                    collaborative activities. The agenda includes:
                </p>
                <ul style="padding-left: 20px; font-size: 16px; color: #444;">
                    <li><strong>Opening Keynote:</strong> Exploring the future of trustworthy AI in immersive XR systems
                    </li>
                    <li><strong>Thematic Sessions:</strong> Peer-reviewed papers and lightning talks</li>
                    <li><strong>Interactive Activities:</strong> Group exploration of:
                        <ul style="padding-left: 20px;">
                            <li>Explainability and robustness in AI-powered XR</li>
                            <li>Ethical handling of biometric data</li>
                            <li>LLM integration in real-time XR systems</li>
                            <li>Privacy, manipulation, and trust frameworks</li>
                        </ul>
                    </li>
                </ul>

                <p style="margin-top: 20px;">
                    For inquiries, contact us at <a href="mailto:trustxr2025@gmail.com">trustxr2025@gmail.com</a>.
                </p>
            </div>
        </section>

        </font>
        <!-- <font size="3"> -->
        <!-- <font size="3"> -->

        <section id="location" class="page-header">
            <h2 style="margin-bottom: 20px; font-size: 28px; font-weight: 700; color: #333;">Location and Date</h2>
            <blockquote style="padding: 15px; background-color: #e6f2ff; border-left: 5px solid #0066cc;">
                <p>
                    The TRUST-XR 2025 workshop will be held in conjunction with <strong>ISMAR 2025</strong> in
                    <strong>October 2025</strong> as a <strong>hybrid event</strong> at <strong>Daejeon, South
                        Korea</strong>.
                </p>
                <p>
                    <em>Exact date and venue details will be updated as they become available.</em>
                </p>
            </blockquote>
        </section>

        <div id="important-dates" class="page-header">
            <h2>Important Dates</h2>
            <ul>
                <li><strong>Paper Submission Deadline:</strong> <em>July 10th, 2025 (23:59 AoE, Thrusday)</em></li>
                <li><strong>Notification of Acceptance:</strong> <em>August 1st, 2025 (23:59 AoE, Friday)</em></li>
                <li><strong>Camera-Ready Submission:</strong> <em>August 15th, 2025 (23:59 AoE, Friday)</em></li>
                <li><strong>Workshop Date:</strong> <em>October 12th, 2025 </em> (Held in conjunction with ISMAR 2025)
                </li>
            </ul>
        </div>
        <!-- <section id="program" class="page-header">

            <h2>Program</h2>
            <div style="padding: 20px; background-color: #e6f2ff; border-left: 5px solid #0066cc;">


                <style>
                    .program-table {
                        background-color: #f7fbfd;
                        /* Light background tint for table */
                    }

                    .program-table thead {
                        background-color: #d9edf7;
                        /* Light blue for header */
                    }

                    .program-table th,
                    .program-table td {
                        width: 8%;
                        vertical-align: top;
                    }

                    .program-table th:nth-child(2),
                    .program-table td:nth-child(2) {
                        width: 62%;
                    }

                    .program-table th:nth-child(3),
                    .program-table td:nth-child(3) {
                        width: 30%;
                    }
                </style>

                <h3>Session 1: Securing Sensors</h3>
                <table class="table table-striped program-table">
                    <thead>
                        <tr>
                            <th>Time</th>
                            <th>Title</th>
                            <th>Speakers / Authors</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>9:00</td>
                            <td>Welcome!</td>
                            <td></td>
                        </tr>
                        <tr>
                            <td>9:10</td>
                            <td>Talk: Secure On-Sensor Machine Learning</td>
                            <td>Swapnil Saha, Mahesh Chowdhary (STMicroelectronics)</td>
                        </tr>
                        <tr>
                            <td>9:35</td>
                            <td>Talk: Security of AV Perception Systems</td>
                            <td>Xugui Zhou (Louisiana State University)</td>
                        </tr>
                        <tr>
                            <td>10:00</td>
                            <td>Paper: Towards Understanding User Privacy Concerns of Internet of Things Sensor Data
                            </td>
                            <td>Dipu Ram Roy (BUET), Jieqiong Zhao (Augusta), Shijia Pan (UC Merced), Shiwei Fang
                                (Augusta)</td>
                        </tr>
                        <tr>
                            <td>10:15</td>
                            <td>Paper: Intermittent Power, Continuous Protection: Security and Privacy for Batteryless
                                Devices in IoT</td>
                            <td>Thea U. Kjeldsmark (UC Irvine), Hui Zhuang (ASU), Habiba Farrukh (UC Irvine), Muslum
                                Ozgur Ozmen (ASU)</td>
                        </tr>
                    </tbody>
                </table>

                <h3>Session 2: Sensing Applications</h3>
                <table class="table table-striped program-table">
                    <thead>
                        <tr>
                            <th>Time</th>
                            <th>Title</th>
                            <th>Speakers / Authors</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>11:00</td>
                            <td>Talk: Towards Trustworthy XR: Safety, Security, and Privacy Concerns in XR in the Era of
                                AI</td>
                            <td>Khaza Anuarul Hoque (University of Missouri)</td>
                        </tr>
                        <tr>
                            <td>11:25</td>
                            <td>Talk: Toward Mobile AI Systems with Physical World Perception</td>
                            <td>Yi Ding (UT Dallas)</td>
                        </tr>
                        <tr>
                            <td>11:50</td>
                            <td>Talk: Attacking mmWave Sensing with Meta-material-enhanced Tags</td>
                            <td>Zhengxiong Li (UC Denver)</td>
                        </tr>
                        <tr>
                            <td>12:15</td>
                            <td>Paper: mmVanish: Extending the Vanish Attack for Multi-Radar Exploitation of mmWave
                                Sensing with Meta-material Tags</td>
                            <td>Xinmin Fang (UC Denver), Hailu Xu (CSU Long Beach), Lingfeng Tao (Oklahoma State),
                                Zhengxiong Li (UC Denver)</td>
                        </tr>
                    </tbody>
                </table>

                <h3>Session 3: Sensing in the Age of Machine Learning</h3>
                <table class="table table-striped program-table">
                    <thead>
                        <tr>
                            <th>Time</th>
                            <th>Title</th>
                            <th>Speakers / Authors</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>2:00</td>
                            <td>Paper: IoTCloak: Practical Integrity Checks of Machine Learning Inference Code and
                                Models on Tiny IoT Devices</td>
                            <td>Mehreen Jabbeen, Vireshwar Kumar, Rijurekha Sen (IIT Delhi)</td>
                        </tr>
                        <tr>
                            <td>2:15</td>
                            <td>Paper: ACLI-DPFL: Differentially Private Federated Learning with Adaptive Clipping and
                                Local Iteration</td>
                            <td>Masanori Nakajima, Yuko Hara (Institute of Science Tokyo)</td>
                        </tr>
                        <tr>
                            <td>2:30</td>
                            <td>Keynote: Safeguarding Media Integrity From The Growing Threat of Generative AI</td>
                            <td>Joseph DeGol (Steg.AI)</td>
                        </tr>
                        <tr>
                            <td>3:00</td>
                            <td>Closing</td>
                            <td></td>
                        </tr>
                    </tbody>
                </table>
        </section> -->
        <section id="organizers" class="page-header">
            <h2 style="margin-bottom: 20px; font-size: 28px; font-weight: 700; color: #333;">Organizers</h2>
            <h3>General Chairs</h3>
            <ul>
                <li><strong><a href="https://engineering.missouri.edu/faculty/khaza-anuarul-hoque/">Khaza Anuarul
                            Hoque</a></strong> (University of Missouri-Columbia, USA)</li>
                <li><strong><a href="https://website.cs.vt.edu/people/faculty/brendan-david-john.html">Brendan
                            David-John</a></strong> (Virginia Tech, USA)</li>
            </ul>

            <h3>Technical Program Chair</h3>
            <ul>
                <li><strong><a href="https://www.linkedin.com/in/ripan-kumar-kundu-9b3b24b9/">Ripan Kumar
                            Kundu</a></strong> (University of Missouri-Columbia, USA)</li>
            </ul>

            <h3>Website Chair</h3>
            <ul>
                <li><strong><a href="https://www.linkedin.com/in/istiak-ahmed-0836601b6/">Istiak Ahmed</a></strong>
                    (University of Missouri-Columbia, USA)</li>
            </ul>

            <h3>Online Session Coordinator</h3>
            <ul>
                <li>
                    <strong>
                        <a href="https://www.linkedin.com/in/azim-ibragimov/">Azim Ibragimov</a>
                    </strong>
                    (University of Florida, USA)
                    <br>Email: <a href="mailto:a.ibragimov@ufl.edu ">a.ibragimov@ufl.edu </a>
                </li>
            </ul>

            <h3>Technical Program Committee</h3>
            <ul>
                <li><strong><a href="https://www.gmu.edu/profiles/xzhang46">Xiaokuan Zhang</a></strong>
                    (George Mason University, USA)</li>
                <li><strong><a href="https://ece.duke.edu/people/maria-gorlatova/">Maria Gorlatova</a></strong>
                    (Duke University, USA)</li>
                <li><strong><a href="https://people.cs.vt.edu/boji/">Bo Ji</a></strong> (Virginia Tech, USA)</li>
                <li><strong><a href="https://sciences.utsa.edu/faculty/profiles/quarles-john.html">John
                            Quarles</a></strong>
                    (University of Texas at San Antonio, USA)</li>
                <li><strong><a href="https://www.cogsci.ucsb.edu/people/barry-giesbrecht">Barry Giesbrecht</a></strong>
                    (University of California Santa Barbara, USA)</li>
                <li><strong><a
                            href="https://www.albany.edu/news-center/news/2024-expert-human-ai-interaction-lead-ualbanys-ai-plus-institute">Balakrishnan
                            Prabhakaran</a></strong>
                    (University at Albany - State University of New York, USA)</li>
                <li><strong><a href="https://www.prasadcalyam.com/">Prasad Calyam</a></strong>
                    (University of Missouri-Columbia, USA)</li>
                <li><strong><a href="https://userweb.cs.txstate.edu/~ok11/">Oleg Komogortsev</a></strong> (Texas State
                    University, USA)</li>
                <li><strong><a href="https://www.kennesaw.edu/ccse/academics/computer-science/faculty-staff.php">M.
                            Rasel Mahmud
                        </a></strong> (Kennesaw State University, USA)</li>
                <li><strong><a href="https://pvfa.tamu.edu/staff/you-jin-kim/">You-Jin Kim
                        </a></strong> (Texas A&M University, USA)</li>
                <li><strong><a href="https://www.lsu.edu/eng/cse/people/faculty/baggili.php">Ibrahim Baggili
                        </a></strong> (Louisiana State University, USA)</li>
                <li><strong><a href="https://ualr.edu/computerscience/aryabrata-basu/">Aryabrata Basu
                        </a></strong> (University of Arkansas at Little Rock, USA)</li>
                <li><strong><a href="https://mallesham.com/">Mallesham Dasari
                        </a></strong> (Northeastern University, USA)</li>
            </ul>
        </section>

        <section id="call-for-paper" class="page-header">
            <div
                style="border-left: 6px solid #0066cc; background-color: #ffffff; padding: 30px; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.05);">
                <h2 style="margin-bottom: 20px; font-size: 28px; font-weight: 700; color: #333;">Topics of Interest</h2>
                <p style="font-size: 16px; color: #444;">
                    The <strong>TRUST-XR 2025</strong> workshop invites contributions related to trustworthy, secure,
                    and privacy-aware AI in XR systems. Topics include, but are not limited to:
                </p>
                <ul style="list-style: none; padding-left: 0; margin-top: 20px;">
                    <li style="margin-bottom: 12px;">
                        <i class="fa fa-check-circle" style="color: #0066cc; margin-right: 8px;"></i>
                        Explainable and interpretable AI models for XR environments
                    </li>
                    <li style="margin-bottom: 12px;">
                        <i class="fa fa-check-circle" style="color: #0066cc; margin-right: 8px;"></i>
                        Privacy-preserving learning for multimodal XR data (e.g., eye-tracking, biometrics)
                    </li>
                    <li style="margin-bottom: 12px;">
                        <i class="fa fa-check-circle" style="color: #0066cc; margin-right: 8px;"></i>
                        Adversarial robustness in AI-driven XR pipelines
                    </li>
                    <li style="margin-bottom: 12px;">
                        <i class="fa fa-check-circle" style="color: #0066cc; margin-right: 8px;"></i>
                        Cognitive security threats and perceptual manipulation in immersive systems
                    </li>
                    <li style="margin-bottom: 12px;">
                        <i class="fa fa-check-circle" style="color: #0066cc; margin-right: 8px;"></i>
                        Ethical frameworks and responsible AI for XR applications
                    </li>
                    <li style="margin-bottom: 12px;">
                        <i class="fa fa-check-circle" style="color: #0066cc; margin-right: 8px;"></i>
                        Generative AI safety in XR content and interaction
                    </li>
                    <li style="margin-bottom: 12px;">
                        <i class="fa fa-check-circle" style="color: #0066cc; margin-right: 8px;"></i>
                        Trust, transparency, and accountability in intelligent XR systems
                    </li>
                    <li style="margin-bottom: 12px;">
                        <i class="fa fa-check-circle" style="color: #0066cc; margin-right: 8px;"></i>
                        Secure multimodal pipelines: visual, audio, haptic, biometric
                    </li>
                    <li style="margin-bottom: 12px;">
                        <i class="fa fa-check-circle" style="color: #0066cc; margin-right: 8px;"></i>
                        Cross-platform XR security (enterprise and consumer devices)
                    </li>
                    <li style="margin-bottom: 12px;">
                        <i class="fa fa-check-circle" style="color: #0066cc; margin-right: 8px;"></i>
                        Human-centered evaluation for trust, privacy, explainability
                    </li>
                    <li style="margin-bottom: 12px;">
                        <i class="fa fa-check-circle" style="color: #0066cc; margin-right: 8px;"></i>
                        Real-world case studies of trustworthy XR deployments
                    </li>
                    <li style="margin-bottom: 12px;">
                        <i class="fa fa-check-circle" style="color: #0066cc; margin-right: 8px;"></i>
                        Bias mitigation in AI models used in XR
                    </li>
                    <li style="margin-bottom: 12px;">
                        <i class="fa fa-check-circle" style="color: #0066cc; margin-right: 8px;"></i>
                        Security implications of integrating LLMs into XR systems
                    </li>
                    <li>
                        <i class="fa fa-check-circle" style="color: #0066cc; margin-right: 8px;"></i>
                        Policy and regulatory perspectives on immersive computing safety
                    </li>
                </ul>
            </div>
        </section>




        <section id="submission-guidelines" class="page-header">
            <h2 style="margin-bottom: 20px; font-size: 28px; font-weight: 700; color: #333;">Submission Guidelines</h2>
            <p>
                We invite submissions that explore the intersection of AI, XR, privacy, and security. Submissions must
                follow the IEEE VGTC formatting guidelines and will be peer-reviewed based on relevance, originality,
                and contribution diversity.
            </p>

            <blockquote style="padding: 10px; background-color: #EEEEEE;">
                <font size="3">
                    <p>We accept the following types of submissions:</p>
                    <ol>
                        <li><strong>Regular Papers:</strong> Upto 8 pages, including references and appendix.</li>
                        <li><strong>Short Papers:</strong> Upto 4 pages, including references</li>
                        <li><strong>Position papers:</strong> Upto 2 pages, including references.</li>
                    </ol>
                </font>
            </blockquote>
            <p>
                At least one author per accepted contribution published in the IEEE Digital Library must be registered
                as an AUTHOR to the FULL conference at the rate of full Member/Non-Member registration regardless of
                whether or not he/she is a student .
            </p>
            <p>
                Papers will be submitted for publication in the <strong>IEEE Digital Library</strong>.
            </p>

            <h3>Formatting</h3>
            <p>
                All submissions should use the <a href="https://tc.computer.org/vgtc/publications/conference/"
                    target="_blank">IEEE VGTC formatting template</a> and be submitted in PDF format. Submissions must
                be original, unpublished, and not currently under review elsewhere.
                Papers that fail to comply with formatting or length limits will be desk-rejected.
            </p>

            <h3>Review Process</h3>
            <p>
                Submissions will be <strong>single-blind</strong> and reviewed by the workshop organizers and program
                committee.
                Each submission will undergo <strong>peer review by at least two domain experts</strong>.
                Accepted papers will be assigned oral or lightning talk presentations based on content and format.
                Acceptance does not restrict future publications authors may present extended or modified versions
                of their work as full papers, short papers, or journal articles, provided they include significant
                new contributions beyond the original workshop submission.
            </p>
            <p>
                <strong>Review decisions are final.</strong> Authors of accepted papers are required to submit a revised
                version
                that addresses the feedback provided in the reviews.
            </p>


            <h3>Submission Site</h3>
            <p>
                <a href="https://easychair.org/conferences?conf=trustxr2025" target="_blank">EasyChair Link</a>
            </p>
        </section>
        <!-- <section id="keynote" class="page-header">
            <h2>Keynote Speakers</h2>

            <div class="row" style="margin-bottom: 40px; display: flex; align-items: flex-start;">
                <div class="col-md-3 text-center">
                    <img src="images/C.png" alt="Dr. Chou P. Hung" class="img-thumbnail"
                        style="width: 100%; max-width: 240px; border: 3px solid #ccc;">
                </div>
                <div class="col-md-9">
                    <h4 style="margin-top: 0;"><strong>Keynote 1:</strong> Trustworthy Attentional Guidance for
                        Real-Virtual Hybrid Environments</h4>
                    <p><strong>Speaker:</strong> Dr. Chou P. Hung, U.S. DEVCOM ARL Army Research Office </p>
                    <p><strong>Biography:</strong> Dr. Chou P. Hung is the Program Manager for Neurophysiology of
                        Cognition at the U.S. DEVCOM ARL
                        Army Research Office and has been a researcher at the DEVCOM Army Research Laboratory since 2015
                        in the areas of human cognition and bio-inspired novel AI development.
                        Previously, he was an Assistant Professor of neuroscience at Georgetown University and at
                        National Yang-Ming University in Taiwan, where he led research to discover neural circuits and
                        representations underlying visual perception.
                        Dr. Hung’s research interests span from living neurons, circuits, mechanisms, and behaviors
                        underlying real-world and augmented perception and performance, to biological and AI-aided
                        learning and decision-making, to brain-inspired computational principles for novel AIs for
                        complex reasoning.
                        He holds a BS in Biology from Caltech (1996), a PhD in Neuroscience from Yale University (2002),
                        and completed his postdoc at MIT (2005).</p>
                </div>
            </div>
            <div class="row" style="margin-bottom: 40px; display: flex; align-items: center;">
                <div class="col-md-3 d-flex justify-content-center align-items-center">
                    <img src="images/C2.png" alt="Dr. Chou P. Hung" class="img-thumbnail"
                        style="width: 100%; max-width: 280px; border: 3px solid #ccc;">
                </div>
                <div class="col-md-9">
                    <h4 style="margin-top: 0;"><strong>Keynote 1:</strong> Trustworthy Attentional Guidance for
                        Real-Virtual Hybrid Environments</h4>
                    <p><strong>Speaker:</strong> Dr. Chou P. Hung, U.S. DEVCOM ARL Army Research Office</p>
                    <p><strong>Biography:</strong> Dr. Chou P. Hung is the Program Manager for Neurophysiology of
                        Cognition at the U.S. DEVCOM ARL Army Research Office and has been a researcher at the DEVCOM
                        Army Research Laboratory since 2015 in the areas of human cognition and bio-inspired novel AI
                        development. Previously, he was an Assistant Professor of neuroscience at Georgetown University
                        and at National Yang-Ming University in Taiwan, where he led research to discover neural
                        circuits and representations underlying visual perception. Dr. Hung’s research interests span
                        from living neurons, circuits, mechanisms, and behaviors underlying real-world and augmented
                        perception and performance, to biological and AI-aided learning and decision-making, to
                        brain-inspired computational principles for novel AIs for complex reasoning. He holds a BS in
                        Biology from Caltech (1996), a PhD in Neuroscience from Yale University (2002), and completed
                        his postdoc at MIT (2005).</p>
                </div>
            </div>


            <div class="row" style="margin-bottom: 40px; display: flex; align-items: center;">
                <div class="col-md-3 d-flex justify-content-center align-items-center">
                    <img src="images/M.png" alt="Dr. Mar Gonzalez-Franco" class="img-thumbnail"
                        style="width: 100%; max-width: 280px; border: 3px solid #ccc;">
                </div>
                <div class="col-md-9">
                    <h4 style="margin-top: 0;"><strong>Keynote 2:</strong> How can XR help building trust on AI? </h4>
                    <p><strong>Speaker:</strong> Dr. Mar Gonzalez-Franco, Google </p>
                    <p><strong>Biography:</strong> Dr. Mar Gonzalez-Franco is a Computer Scientist and Neuroscientist.
                        She is currently a Research Scientist Manager at Google
                        where she leads the Blended Interactions and Devices Research lab working on a new generation of
                        Immersive technologies and generative AI, focused on
                        input interactions and experiences. Her team has envisioned Android XR multimodal and
                        multidevice interactions to the OS and unified input vocabularies.
                        Before working at Google, she was a Principal Researcher at Microsoft Research where she built
                        new features for products such as Xbox, Hololens, Soundscape and Teams.
                        Her main tech transfer at Microsoft, was Avatars on MS Teams that is available on daily basis to
                        over 260 million users, and won Times Invention of the year 2022.
                        Her technical work has produced over 40 patents (some pending), and +10 open-source projects
                        including some of the most used avatar libraries (Microsoft Rocketbox, UCF-Google VALID),
                        and Immersive AI pipelines and Datasets (XR-Objects, Diffseg, PARSE-Ego4D). Apart from her
                        technological contributions, she is a prolific scientist with over 100 publications and does
                        regular service
                        as program committee, chair and reviewer in top venues (ACM, IEEE, Nature Publishing, Royal
                        Society, AAAS Science) and governments (UN, EU, NSF, NSERC). She was awarded the IEEE VGTC VR
                        New
                        researcher award in 2022, the NAE early-career engineer, and the 2025 ACM SIGCHI Special
                        Recognition of pioneering Input and Interaction guidelines in the Android XR Operating System.
                    </p>
                </div>
            </div>
        </section> -->

        <section id="keynote" class="page-header">
            <!-- <h2 style="margin-bottom: 30px; font-weight: bold; font-size: 32px;">Keynote Speakers</h2> -->
            <h2 style="margin-bottom: 20px; font-size: 28px; font-weight: 700; color: #333;">Keynote Speakers</h2>

            <div class="row"
                style="margin-bottom: 40px; background-color: #f9f9f9; padding: 20px; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
                <div class="col-md-3 d-flex justify-content-center align-items-center">
                    <img src="images/C2.png" alt="Dr. Chou P. Hung" class="img-thumbnail"
                        style="width: 100%; max-width: 280px; border-radius: 10px;">
                </div>
                <div class="col-md-9">
                    <h4 style="margin-top: 0;"><strong>Keynote 1:</strong> Trustworthy Attentional Guidance for
                        Real-Virtual Hybrid Environments</h4>
                    <p><strong>Speaker:</strong> Dr. Chou P. Hung, U.S. DEVCOM ARL Army Research Office</p>
                    <p><strong>Biography:</strong> <span style="text-align: justify; display: block;">Dr. Chou P. Hung
                            is the Program Manager for Neurophysiology of
                            Cognition at the U.S. DEVCOM ARL Army Research Office and has been a researcher at the
                            DEVCOM
                            Army Research Laboratory since 2015 in the areas of human cognition and bio-inspired novel
                            AI
                            development. Previously, he was an Assistant Professor of neuroscience at Georgetown
                            University
                            and at National Yang-Ming University in Taiwan, where he led research to discover neural
                            circuits and representations underlying visual perception. Dr. Hung’s research interests
                            span
                            from living neurons, circuits, mechanisms, and behaviors underlying real-world and augmented
                            perception and performance, to biological and AI-aided learning and decision-making, to
                            brain-inspired computational principles for novel AIs for complex reasoning. He holds a BS
                            in
                            Biology from Caltech (1996), a PhD in Neuroscience from Yale University (2002), and
                            completed
                            his postdoc at MIT (2005).</span></p>
                </div>
            </div>

            <div class="row"
                style="margin-bottom: 40px; background-color: #f9f9f9; padding: 20px; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
                <div class="col-md-3 d-flex justify-content-center align-items-center">
                    <img src="images/M.png" alt="Dr. Mar Gonzalez-Franco" class="img-thumbnail"
                        style="width: 100%; max-width: 280px; border-radius: 10px;">
                </div>
                <div class="col-md-9">
                    <h4 style="margin-top: 0;"><strong>Keynote 2:</strong> How can XR help building trust on AI?</h4>
                    <p><strong>Speaker:</strong> Dr. Mar Gonzalez-Franco, Google</p>
                    <p><strong>Biography:</strong><span style="text-align: justify; display: block;"> Dr. Mar
                            Gonzalez-Franco is a Computer Scientist and Neuroscientist.
                            She is currently a Research Scientist Manager at Google where she leads the Blended
                            Interactions
                            and Devices Research lab working on a new generation of Immersive technologies and
                            generative
                            AI, focused on input interactions and experiences. Her team has envisioned Android XR
                            multimodal
                            and multidevice interactions to the OS and unified input vocabularies. Before working at
                            Google,
                            she was a Principal Researcher at Microsoft Research where she built new features for
                            products
                            such as Xbox, Hololens, Soundscape and Teams. Her main tech transfer at Microsoft, was
                            Avatars
                            on MS Teams that is available on daily basis to over 260 million users, and won Times
                            Invention
                            of the year 2022. Her technical work has produced over 40 patents (some pending), and +10
                            open-source projects including some of the most used avatar libraries (Microsoft Rocketbox,
                            UCF-Google VALID), and Immersive AI pipelines and Datasets (XR-Objects, Diffseg,
                            PARSE-Ego4D).
                            Apart from her technological contributions, she is a prolific scientist with over 100
                            publications and does regular service as program committee, chair and reviewer in top venues
                            (ACM, IEEE, Nature Publishing, Royal Society, AAAS Science) and governments (UN, EU, NSF,
                            NSERC). She was awarded the IEEE VGTC VR New researcher award in 2022, the NAE early-career
                            engineer, and the 2025 ACM SIGCHI Special Recognition of pioneering Input and Interaction
                            guidelines in the Android XR Operating System.</span></p>
                </div>
            </div>
        </section>












        <section id="program" class="page-header">
            <h2 style="margin-bottom: 20px; font-size: 28px; font-weight: 700; color: #333;">Tentative Program</h2>
            <div style="padding: 20px; background-color: #e6f2ff; border-left: 5px solid #0066cc;">

                <style>
                    .program-table {
                        background-color: #f7fbfd;
                    }

                    .program-table thead {
                        background-color: #d9edf7;
                    }

                    .program-table th,
                    .program-table td {
                        vertical-align: top;
                    }

                    .program-table th:nth-child(1),
                    .program-table td:nth-child(1) {
                        width: 25%;
                    }

                    .program-table th:nth-child(2),
                    .program-table td:nth-child(2) {
                        width: 35%;
                    }

                    .program-table th:nth-child(3),
                    .program-table td:nth-child(3) {
                        width: 40%;
                    }
                </style>

                <h3>Session I: Welcome and Keynote</h3>
                <table class="table table-striped program-table">
                    <thead>
                        <tr>
                            <th>Time</th>
                            <th>Title</th>
                            <th>Details</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>8:30 AM - 9:00 AM</td>
                            <td>Arrival and Setup</td>
                            <td></td>
                        </tr>
                        <tr>
                            <td>9:00 AM - 9:10 AM</td>
                            <td>Welcome & Introduction</td>
                            <td>Overview of Workshop Themes and Goals</td>
                        </tr>
                        <tr>
                            <td>9:10 AM - 9:30 AM</td>
                            <td>Opening Keynote</td>
                            <td>Trustworthy Attentional Guidance for Real-Virtual Hybrid Environments by Dr. Chou P.
                                Hung
                            </td>
                        </tr>
                    </tbody>
                </table>

                <h3>Session II: Paper and Lightning Talks – Part 1</h3>
                <table class="table table-striped program-table">
                    <thead>
                        <tr>
                            <th>Time</th>
                            <th>Title</th>
                            <th>Details</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>9:30 AM - 10:30 AM</td>
                            <td>Paper Presentations</td>
                            <td>TBA</td>
                        </tr>
                        <tr>
                            <td>10:30 AM</td>
                            <td>Break</td>
                            <td></td>
                        </tr>
                    </tbody>
                </table>

                <h3>Session III: Paper and Lightning Talks – Part 2</h3>
                <table class="table table-striped program-table">
                    <thead>
                        <tr>
                            <th>Time</th>
                            <th>Title</th>
                            <th>Details</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>11:00 AM - 12:00 PM</td>
                            <td>Paper Presentations (continued)</td>
                            <td>Short papers</td>
                        </tr>
                        <tr>
                            <td>12:00 PM</td>
                            <td>Lunch Break</td>
                            <td></td>
                        </tr>
                    </tbody>
                </table>

                <h3>Session IV: Paper and Lightning Talks – Part 3</h3>
                <table class="table table-striped program-table">
                    <thead>
                        <tr>
                            <th>Time</th>
                            <th>Title</th>
                            <th>Details</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>2:00 PM - 2:20 PM</td>
                            <td>Keynote 2</td>
                            <td>How can XR help building trust on AI? <br> by Dr. Mar Gonzalez-Franco</td>
                        </tr>
                        <tr>
                            <td>2:20 PM - 3:00 PM</td>
                            <td>Paper Presentations</td>
                            <td>TBA</td>
                        </tr>
                        <tr>
                            <td>3:00 PM</td>
                            <td>Break</td>
                            <td></td>
                        </tr>
                    </tbody>
                </table>

                <h3>Session V: Activity II – Future Directions</h3>
                <table class="table table-striped program-table">
                    <thead>
                        <tr>
                            <th>Time</th>
                            <th>Title</th>
                            <th>Details</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>3:30 PM - 4:45 PM</td>
                            <td>Collaborative Brainstorming</td>
                            <td>Future Research Directions for Secure, Ethical, and Trustworthy AIXR Systems</td>
                        </tr>
                        <tr>
                            <td>4:45 PM</td>
                            <td>Closing Remarks</td>
                            <td>Summary and Next Steps</td>
                        </tr>
                    </tbody>
                </table>

            </div>
        </section>

        <footer style="text-align:center;">
            <img src="images/trustxr-logo.png" alt="TRUST-XR Logo" style="max-height: 40px; margin-bottom: 10px;"><br>
            <p>&copy; 2025 Trust XR Workshop. All Rights Reserved.</p>
        </footer>

    </div>

    <script src="./theme/jquery.min.js"></script>
    <script src="./theme/bootstrap.min.js"></script>
    <script>
        $(document).ready(function () {
            $('a[href^="#"]').on('click', function (e) {
                e.preventDefault();
                $('html, body').animate({
                    scrollTop: $($(this).attr('href')).offset().top - 70
                }, 800);
            });
        });
    </script>

</body>

</html>